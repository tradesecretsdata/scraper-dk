AWSTemplateFormatVersion: '2010-09-09'
Transform: AWS::Serverless-2016-10-31
Description: Serverless scraping pipeline

Parameters:
  Env:               # stage | prod
    Type: String
    AllowedValues: [stage, prod]
  BucketName:
    Type: String
  S3Prefix:
    Type: String
  RoleArn:
    Type: String
  ApiUrl:            
    Type: String
    Default: ""

Globals:
  Function:
    Runtime: python3.12
    MemorySize: 128
    Timeout: 30
    Architectures: [arm64]
    Handler: handler.lambda_handler
    Environment:
      Variables:
        RAW_PREFIX: !Sub "${S3Prefix}/${Env}/raw"
        PROC_PREFIX: !Sub "${S3Prefix}/${Env}/processed"
        DB_URI: !Sub "s3://${BucketName}/${S3Prefix}/${Env}/db/scraper-dk.duckdb"
        API_URL: !Ref ApiUrl
        BUCKET_NAME: tradesecretsdata

Resources:
  ScraperFunction:
    Type: AWS::Serverless::Function
    Properties:
      CodeUri: src/
      Role:  !Ref RoleArn
      Events:
        FiveMinuteSchedule:
          Type: Schedule
          Properties:
            Schedule: !If
              - IsProd
              - "rate(5 minutes)"
              - "rate(30 minutes)"
      Layers: []          # add libs layer if size > 250Â MB

  # OPTIONAL: CloudWatch metric + alarm straight in CFN
  ErrorAlarm:
    Type: AWS::CloudWatch::Alarm
    Properties:
      AlarmName: !Sub "${Env}-scraper-errors"
      MetricName: Errors
      Namespace: AWS/Lambda
      Dimensions:
        - Name: FunctionName
          Value: !Ref ScraperFunction
      Statistic: Sum
      Period: 900
      EvaluationPeriods: 1
      Threshold: 1
      ComparisonOperator: GreaterThanOrEqualToThreshold
      TreatMissingData: notBreaching
      AlarmActions: []   # fill with SNS ARN if you wired one

Conditions:
  IsProd: !Equals [ !Ref Env, "prod" ]

Outputs:
  FunctionArn: { Value: !GetAtt ScraperFunction.Arn }
  BucketName:  { Value: !Ref BucketName }
